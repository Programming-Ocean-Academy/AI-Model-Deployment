{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Structured Map of Deployment Platforms**  \n",
        "*A hierarchical, clean, academically structured atlas of all deployment platforms you listed — organized as a tree-style map.*\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Hyperscaler Cloud AI Platforms (End-to-End / Managed)**  \n",
        "*Full MLOps: training → deployment → monitoring → pipelines.*\n",
        "\n",
        "## **1.1 AWS**\n",
        "- Amazon SageMaker (full MLOps)\n",
        "- AWS Lambda + API Gateway (serverless inference)\n",
        "- Amazon ECS / EKS (container orchestration)\n",
        "- Amazon EC2 (custom serving stack)\n",
        "- Amazon Bedrock (managed foundation models)\n",
        "\n",
        "## **1.2 Google Cloud Platform (GCP)**\n",
        "- Vertex AI (training, prediction, registry)\n",
        "- AI Platform Prediction (legacy)\n",
        "- GKE (KServe, Seldon)\n",
        "- Cloud Run (serverless containers)\n",
        "- Compute Engine (custom VMs)\n",
        "\n",
        "## **1.3 Microsoft Azure**\n",
        "- Azure Machine Learning (training + endpoints)\n",
        "- Azure Kubernetes Service (AKS)\n",
        "- Azure Functions\n",
        "- Azure OpenAI Service (managed LLM endpoints)\n",
        "\n",
        "---\n",
        "\n",
        "# **2. Specialized MLOps & Model Deployment Platforms (Cloud-Agnostic)**  \n",
        "*Focus on serving, CI/CD, lifecycle, multi-cloud or on-prem.*\n",
        "\n",
        "- Databricks ML (MLflow + registry + endpoints)\n",
        "- Snowflake Cortex / Snowpark ML\n",
        "- MLflow (open-source)\n",
        "- Kubeflow (Kubernetes-native MLOps)\n",
        "- KServe (standard inference for Kubernetes)\n",
        "- Seldon Core (Kubernetes model serving)\n",
        "- BentoML (model packaging + Docker + K8s)\n",
        "- Ray Serve (distributed Python/LLM serving)\n",
        "- MLRun / Iguazio\n",
        "- ClearML (tracking + orchestration + serving)\n",
        "- Domino Data Lab\n",
        "- H2O MLOps / H2O Cloud\n",
        "- DVC + CML (CI/CD workflow)\n",
        "\n",
        "---\n",
        "\n",
        "# **3. Serverless GPU / “Inference-as-a-Service” Platforms**  \n",
        "*Push model → get HTTPS endpoint → GPU autoscaling.*\n",
        "\n",
        "- Modal\n",
        "- Replicate\n",
        "- Banana.dev\n",
        "- RunPod (serverless endpoints + pods)\n",
        "- Paperspace / Gradient\n",
        "- Beam\n",
        "- Cortex (open-source origins)\n",
        "- Baseten\n",
        "- OctoAI (ex-OctoML)\n",
        "- Anyscale (Ray-based serving)\n",
        "- Lightning AI\n",
        "\n",
        "---\n",
        "\n",
        "# **4. LLM-Specific Hosting / API Platforms**  \n",
        "*You deploy your **application**, not your weights.*\n",
        "\n",
        "- OpenAI API\n",
        "- Anthropic (Claude)\n",
        "- Google AI Studio / Gemini API\n",
        "- Cohere\n",
        "- Mistral AI\n",
        "- AI21 Labs\n",
        "- xAI (Grok)\n",
        "- Perplexity API\n",
        "\n",
        "---\n",
        "\n",
        "# **5. Open-Source Model Servers & Runtimes (Self-Hosted)**  \n",
        "\n",
        "## **5.1 General Deep Learning Model Servers**\n",
        "- NVIDIA Triton Inference Server\n",
        "- TensorFlow Serving\n",
        "- TorchServe\n",
        "- ONNX Runtime / ORTServer\n",
        "- DJL Serving\n",
        "- MLServer (Seldon)\n",
        "\n",
        "## **5.2 LLM-Focused Runtimes**\n",
        "- vLLM (PagedAttention; high throughput)\n",
        "- TGI — Text Generation Inference (Hugging Face)\n",
        "- FastChat\n",
        "- llama.cpp servers (C++ inference)\n",
        "- Ollama (desktop/server LLMs)\n",
        "- OpenLLM (BentoML)\n",
        "\n",
        "---\n",
        "\n",
        "# **6. Hugging Face Ecosystem**  \n",
        "*Models, autoscaling, CI/CD, optimized runtimes.*\n",
        "\n",
        "- HF Inference Endpoints (managed)\n",
        "- HF Spaces (demos: Gradio, Streamlit)\n",
        "- HF Text Generation Inference (TGI)\n",
        "- HF Hub + CI/CD integrations\n",
        "\n",
        "---\n",
        "\n",
        "# **7. Data Warehouse / BI-Integrated Inference**  \n",
        "*ML inference inside analytics engines.*\n",
        "\n",
        "- BigQuery ML\n",
        "- Snowflake Cortex / Snowpark ML\n",
        "- Redshift ML\n",
        "- Databricks SQL UDF inference\n",
        "\n",
        "---\n",
        "\n",
        "# **8. Edge / Mobile / On-Device Deployment Platforms**\n",
        "\n",
        "## **8.1 Mobile/Edge Runtimes**\n",
        "- TensorFlow Lite (TFLite)\n",
        "- Core ML (Apple)\n",
        "- ONNX Runtime Mobile\n",
        "- TensorRT / TensorRT-LLM\n",
        "- OpenVINO (Intel)\n",
        "- MediaPipe\n",
        "\n",
        "## **8.2 Edge / IoT Platforms**\n",
        "- NVIDIA Jetson + JetPack\n",
        "- Azure IoT Edge\n",
        "- AWS IoT Greengrass\n",
        "- Google Edge TPU (Coral)\n",
        "\n",
        "---\n",
        "\n",
        "# **9. Enterprise AI Suites (Workflow + Deployment + Governance)**\n",
        "\n",
        "- IBM Watson Studio / WML\n",
        "- SAS Viya\n",
        "- DataRobot\n",
        "- H2O Driverless AI / H2O MLOps\n",
        "- RapidMiner\n",
        "- SAP AI Core / Launchpad\n",
        "- Salesforce Einstein\n",
        "\n",
        "---\n",
        "\n",
        "# **10. Vector DBs & RAG-Oriented Platforms**  \n",
        "*Critical for LLM apps, retrieval, and serving pipelines.*\n",
        "\n",
        "- Pinecone\n",
        "- Weaviate\n",
        "- Qdrant\n",
        "- Milvus\n",
        "- Chroma\n",
        "- LlamaIndex (framework)\n",
        "- LangChain (agents/RAG + API deployment)\n",
        "\n",
        "---\n",
        "\n",
        "# **11. API Gateways, Functions & Generic Hosting (Glue Layer)**  \n",
        "*Wrap models as APIs.*\n",
        "\n",
        "## **11.1 Serverless Functions**\n",
        "- AWS Lambda  \n",
        "- Google Cloud Functions  \n",
        "- Azure Functions  \n",
        "\n",
        "## **11.2 API Gateways**\n",
        "- AWS API Gateway\n",
        "- GCP API Gateway\n",
        "- Azure API Management\n",
        "- NGINX / Traefik / Kong\n",
        "\n",
        "## **11.3 Generic Hosting / Containers**\n",
        "- Heroku\n",
        "- Render\n",
        "- Railway\n",
        "- Fly.io\n",
        "- Docker + Kubernetes (on any infra)\n",
        "\n",
        "---\n",
        "\n",
        "# **12. On-Prem / Self-Managed MLOps Stacks**  \n",
        "*Air-gapped, regulated, enterprise environments.*\n",
        "\n",
        "- OpenShift AI (Red Hat)\n",
        "- Rancher + KServe / Kubeflow / Seldon\n",
        "- VMware Tanzu\n",
        "- Canonical Charmed Kubeflow\n",
        "- Determined AI / Hyperparameter\n",
        "\n",
        "---\n",
        "\n",
        "# **13. Small / Classical ML & AutoML Deployment**\n",
        "\n",
        "- scikit-learn + joblib (Flask/FastAPI)\n",
        "- AutoML tools: AutoKeras, TPOT, FLAML, Auto-sklearn, H2O AutoML\n",
        "- R-based: Shiny, Plumber APIs\n",
        "\n",
        "---\n",
        "\n",
        "# **14. Agent & Workflow-Oriented Platforms (LLM Era)**  \n",
        "*LLM applications, agent graphs, automation pipelines.*\n",
        "\n",
        "- LangGraph / LangChain + LangServe\n",
        "- DAGWorks / Hamilton / Prefect / Airflow\n",
        "- n8n / Zapier / Make\n",
        "- Flowise\n",
        "- Dify\n",
        "- OpenWebUI\n",
        "\n",
        "---\n",
        "\n",
        "# **How to Use This Map**\n",
        "This atlas can be extended into:\n",
        "\n",
        "- A decision matrix for choosing a platform  \n",
        "- Architectures for **tiny**, **mid-size**, and **large-scale LLM** deployments  \n",
        "- A visual hierarchical diagram (tree / mind map / taxonomy)  \n",
        "- A recommendation system based on your use-case (web app, edge, HPC, serverless, etc.)\n",
        "\n"
      ],
      "metadata": {
        "id": "SlAk5zaVWGpm"
      }
    }
  ]
}